[comment]: <> (Code generated by mdatagen. DO NOT EDIT.)

# databricksreceiver

## Metrics

These are the metrics available for this scraper.

| Name | Description | Unit | Type | Attributes |
| ---- | ----------- | ---- | ---- | ---------- |
| **databricks.jobs.active.total** | A snapshot of the number of active jobs taken at each scrape | {jobs} | Gauge(Int) | <ul> </ul> |
| **databricks.jobs.run.duration** | The execution duration in milliseconds per completed job | ms | Gauge(Int) | <ul> <li>job_id</li> </ul> |
| **databricks.jobs.schedule.status** | A snapshot of the pause/run status per job taken at each scrape 0=PAUSED, 1=UNPAUSED, 2=NOT_SCHEDULED | {status} | Gauge(Int) | <ul> <li>job_id</li> </ul> |
| **databricks.jobs.total** | A snapshot of the total number of jobs registered in the Databricks instance taken at each scrape | {jobs} | Gauge(Int) | <ul> </ul> |
| **databricks.spark.blockmanager.memory.diskspaceused** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.maxmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.maxoffheapmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.maxonheapmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.memused** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.offheapmemused** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.onheapmemused** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.remainingmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.remainingoffheapmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.blockmanager.memory.remainingonheapmem** | tbd | mb | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.dagscheduler.job.activejobs** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.dagscheduler.job.alljobs** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.dagscheduler.stage.failedstages** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.dagscheduler.stage.runningstages** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.dagscheduler.stage.waitingstages** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.directpoolmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.jvmheapmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.jvmoffheapmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.majorgccount** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.majorgctime** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.mappedpoolmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.minorgccount** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.minorgctime** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.offheapexecutionmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.offheapstoragememory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.offheapunifiedmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.onheapexecutionmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.onheapstoragememory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.onheapunifiedmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreejvmrssmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreejvmvmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreeotherrssmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreeothervmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreepythonrssmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.executormetrics.processtreepythonvmemory** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.jvmcpu.jvmcputime** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.livelistenerbus.queue.appstatus.size** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.livelistenerbus.queue.executormanagement.size** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.livelistenerbus.queue.shared.size** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.livelistenerbus.queue.streams.size** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.spark.sparksqloperationmanager.numhiveoperations** | tbd |  | Gauge(Int) | <ul> <li>cluster_id</li> <li>app_id</li> </ul> |
| **databricks.tasks.run.duration** | The execution duration in milliseconds per completed task | ms | Gauge(Int) | <ul> <li>job_id</li> <li>task_id</li> </ul> |
| **databricks.tasks.schedule.status** | A snapshot of the pause/run status per task taken at each scrape 0=PAUSED, 1=UNPAUSED, 2=NOT_SCHEDULED | {status} | Gauge(Int) | <ul> <li>job_id</li> <li>task_id</li> <li>task_type</li> </ul> |

**Highlighted metrics** are emitted by default. Other metrics are optional and not emitted by default.
Any metric can be enabled or disabled with the following scraper configuration:

```yaml
metrics:
  <metric_name>:
    enabled: <true|false>
```

## Resource attributes

| Name | Description | Type |
| ---- | ----------- | ---- |
| databricks.instance.name | The name of the Databricks instance as defined by the value of the "instance_name" field in the config | Str |

## Metric attributes

| Name | Description | Values |
| ---- | ----------- | ------ |
| app_id | tbd |  |
| cluster_id | tbd |  |
| job_id | The numeric ID of the Databricks job |  |
| task_id | The name of the Databricks task |  |
| task_type | The type of the Databricks task | NotebookTask, SparkJarTask, SparkPythonTask, PipelineTask, PythonWheelTask, SparkSubmitTask |
